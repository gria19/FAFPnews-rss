from crawler.fetch_fp import fetch_latest_fp_articles
from crawler.fetch_fa import fetch_latest_fa_articles  # å¦‚æœä½ ä¹ŸæŠ“ FA
from summarizer.summarize import summarize_article
from rss.generate_feed import generate_rss

import os
print("ğŸ” OPENAI_API_KEY =", os.getenv("OPENAI_API_KEY"))

print("ğŸ” è·å–æ–‡ç« é“¾æ¥ä¸­...")

# âœ… å¦‚æœä½ åªæŠ“ FPï¼Œåˆ™æ³¨é‡Šæ‰ FA éƒ¨åˆ†
articles = fetch_latest_fp_articles()
# articles = fetch_latest_fp_articles() + fetch_latest_fa_articles()

print(f"âœ… æŠ“åˆ° {len(articles)} ç¯‡æ–‡ç« ")

feed_items = []

for article in articles:
    print(f"ğŸŒ æ­£åœ¨ç”Ÿæˆæ‘˜è¦ï¼š{article['title']} - {article['url']}")
    content = article.get("content")
    if not content:
        print("âš ï¸ æ— å†…å®¹ï¼Œè·³è¿‡")
        continue

    summary = summarize_article(article["title"], content)
    feed_items.append({
        "title": article["title"],
        "url": article["url"],
        "summary": summary
    })

generate_rss(feed_items, "rss.xml")
